{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df79d3f0",
   "metadata": {},
   "source": [
    "### Passo 1 — Setup inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f015e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1090f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5765cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a434a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretórios\n",
    "DATASET_DIR = \"/Users/pedrofs/Library/CloudStorage/OneDrive-ISCTE-IUL/Mestrado/2ªSem/APVC/Projeto/dataset/augmented-flat\"\n",
    "BATCH_SIZE = 32\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Garantir reprodutibilidade\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# Verificar se há GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "print(\"Device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670f71eb",
   "metadata": {},
   "source": [
    "### Passo 2 — Transformações e divisão do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e96ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformações\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Carregamento inicial com ImageFolder\n",
    "full_dataset = datasets.ImageFolder(DATASET_DIR)\n",
    "\n",
    "# Lista de índices e classes\n",
    "num_classes = len(full_dataset.classes)\n",
    "class_names = full_dataset.classes\n",
    "print(f\"Total de classes: {num_classes}\")\n",
    "\n",
    "# Split dos índices\n",
    "dataset_size = len(full_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "train_idx, valtest_idx = train_test_split(indices, test_size=0.2, random_state=RANDOM_SEED, stratify=[full_dataset.targets[i] for i in indices])\n",
    "val_idx, test_idx = train_test_split(valtest_idx, test_size=0.5, random_state=RANDOM_SEED, stratify=[full_dataset.targets[i] for i in valtest_idx])\n",
    "\n",
    "# Subsets com transformações apropriadas\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "val_dataset = Subset(full_dataset, val_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)\n",
    "\n",
    "# Substituir transformações em cada subset\n",
    "train_dataset.dataset.transform = train_transforms\n",
    "val_dataset.dataset.transform = val_test_transforms\n",
    "test_dataset.dataset.transform = val_test_transforms\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43085c83",
   "metadata": {},
   "source": [
    "### Passo 3 — Modelo, loss function, otimizador e setup de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48523f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo pré-treinado\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Congelar pesos da rede base\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Substituir a última camada para o número de clubes\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(class_names))\n",
    "\n",
    "# Enviar modelo para o dispositivo\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "# Função de perda (problema multiclasse)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Otimizador (só para a camada final)\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=1e-4)\n",
    "\n",
    "# Parâmetros do treino\n",
    "NUM_EPOCHS = 50\n",
    "PATIENCE = 5  # early stopping\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "\n",
    "# Caminho para guardar o melhor modelo\n",
    "BEST_MODEL_PATH = \"best_model.pt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc83acb",
   "metadata": {},
   "source": [
    "### Passo 4 — Loop de treino "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for inputs, labels in tqdm(dataloader):\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc = running_corrects.float() / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed788161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            val_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_loss = val_loss / len(dataloader.dataset)\n",
    "    epoch_acc = val_corrects.float() / len(dataloader.dataset)\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e271a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"\\nÉpoca {epoch+1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"train_acc\"].append(train_acc.item())\n",
    "    history[\"val_acc\"].append(val_acc.item())\n",
    "\n",
    "    print(f\"Treino — Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    print(f\"Validação — Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        print(\" Novo melhor modelo encontrado. A guardar...\")\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\" Sem melhoria. Early stopping em {epochs_no_improve}/{PATIENCE}\")\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(\" Early stopping ativado.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed0da5",
   "metadata": {},
   "source": [
    "### Passo 5 — Visualização do desempenho do treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752d6a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico da loss\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history[\"train_loss\"], label=\"Treino\")\n",
    "plt.plot(history[\"val_loss\"], label=\"Validação\")\n",
    "plt.title(\"Loss por época\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Gráfico da accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history[\"train_acc\"], label=\"Treino\")\n",
    "plt.plot(history[\"val_acc\"], label=\"Validação\")\n",
    "plt.title(\"Accuracy por época\")\n",
    "plt.xlabel(\"Época\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb213ac",
   "metadata": {},
   "source": [
    "### Passo 6.1 — Avaliação no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f017d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o melhor modelo\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "model.eval()\n",
    "\n",
    "# Prever o conjunto de teste\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "# Métricas globais\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred, average='macro')\n",
    "recall = recall_score(y_true, y_pred, average='macro')\n",
    "f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision (macro): {precision:.4f}\")\n",
    "print(f\"Recall (macro): {recall:.4f}\")\n",
    "print(f\"F1 Score (macro): {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb1725f",
   "metadata": {},
   "source": [
    "### Passo 6.2 — Matrizes de confusão por liga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec263a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "# Carregar o mapeamento\n",
    "with open(os.path.join(DATASET_DIR, \"..\", \"augmented-flat\", \"clube_para_liga.json\")) as f:\n",
    "    clube_para_liga = json.load(f)\n",
    "\n",
    "# Inverter mapping: liga → [classes]\n",
    "liga_to_classes = defaultdict(list)\n",
    "for i, name in enumerate(class_names):\n",
    "    liga = clube_para_liga.get(name, \"desconhecida\")\n",
    "    liga_to_classes[liga].append(i)\n",
    "\n",
    "# Criar matrizes por liga\n",
    "for liga, class_indices in liga_to_classes.items():\n",
    "    liga_labels = []\n",
    "    liga_preds = []\n",
    "\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt in class_indices:\n",
    "            liga_labels.append(yt)\n",
    "            liga_preds.append(yp)\n",
    "\n",
    "    if not liga_labels:\n",
    "        continue\n",
    "\n",
    "    cm_liga = confusion_matrix(liga_labels, liga_preds, labels=class_indices)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    labels = [class_names[i] for i in class_indices]\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_liga, display_labels=labels)\n",
    "    disp.plot(ax=ax, xticks_rotation=90, cmap=\"Oranges\")\n",
    "    plt.title(f\"Matriz de Confusão — {liga}\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
